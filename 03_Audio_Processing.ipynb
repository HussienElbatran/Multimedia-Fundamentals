{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multimedia Processing Course - Part 3: Audio Processing\n",
                "\n",
                "In this notebook, we explore Sound. We will look at audio not just as a waveform over time, but also understand its frequency content.\n",
                "\n",
                "**Content:**\n",
                "1.  **Level 1 (Basic)**: Loading and visualizing Waveforms.\n",
                "2.  **Level 2 (Intermediate)**: Manipulating Audio (Volume, Speed).\n",
                "3.  **Level 3 (Advanced)**: Frequency Domain (FFT) and Spectrograms."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import scipy.io.wavfile as wav\n",
                "\n",
                "# Load the audio\n",
                "samplerate, data = wav.read('datasets/sample_audio.wav')\n",
                "print(f\"Sample Rate: {samplerate} Hz\")\n",
                "print(f\"Duration: {len(data)/samplerate:.2f} s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "We loaded the audio using `scipy.io.wavfile`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Level 1: Time Domain\n",
                "The most basic visualization is the waveform: Amplitude vs Time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a time axis\n",
                "time = np.linspace(0, len(data) / samplerate, num=len(data))\n",
                "\n",
                "plt.figure(figsize=(12, 4))\n",
                "plt.plot(time, data)\n",
                "plt.title(\"Audio Waveform\")\n",
                "plt.xlabel(\"Time (s)\")\n",
                "plt.ylabel(\"Amplitude\")\n",
                "plt.xlim(0, 0.05) # Zoom in to first 0.05 seconds to see the wave\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "We use `np.linspace` to generate time values corresponding to each sample."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Level 2: Simple Manipulation\n",
                "Since audio is just a NumPy array, we can do math on it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Increase Volume (Multiply by constant)\n",
                "quieter_audio = data * 0.5\n",
                "\n",
                "# Reverse Audio\n",
                "reversed_audio = data[::-1]\n",
                "\n",
                "# Save the manipulated audio\n",
                "wav.write('datasets/reversed_audio.wav', samplerate, reversed_audio.astype(np.int16))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "`data * 0.5` halves the amplitude (quieter).\n",
                "`data[::-1]` reverses the array (plays backwards).\n",
                "`wav.write` saves it back to disk."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Level 3: Frequency Domain (The Spectral View)\n",
                "Sounds are vibrations. We often want to know *what frequencies* are present (e.g., detecting a specific musical note). We use the **Fourier Transform**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform FFT (Fast Fourier Transform)\n",
                "fft_spectrum = np.fft.rfft(data)\n",
                "freqs = np.fft.rfftfreq(len(data), 1/samplerate)\n",
                "\n",
                "# Plot the magnitude spectrum\n",
                "plt.figure(figsize=(12, 4))\n",
                "plt.plot(freqs, np.abs(fft_spectrum))\n",
                "plt.title(\"Frequency Spectrum\")\n",
                "plt.xlabel(\"Frequency (Hz)\")\n",
                "plt.ylabel(\"Magnitude\")\n",
                "plt.xlim(0, 1000) # Zoom in to relevant frequencies\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "`np.fft.rfft` computes the Discrete Fourier Transform for real analysis.\n",
                "You should see a spike at 440 Hz (if using the generated sine wave), which corresponds to the note A4."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Spectrogram\n",
                "A spectrum shows frequencies for the *whole* duration. A **Spectrogram** shows how frequencies change *over time*."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 6))\n",
                "plt.specgram(data, Fs=samplerate, NFFT=1024, noverlap=512, cmap='inferno')\n",
                "plt.title(\"Spectrogram\")\n",
                "plt.ylabel(\"Frequency (Hz)\")\n",
                "plt.xlabel(\"Time (s)\")\n",
                "plt.colorbar(label=\"Intensity (dB)\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "`plt.specgram` computes and plots the spectrogram. Brighter colors mean stronger frequencies at that time."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}