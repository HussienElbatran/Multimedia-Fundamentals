{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multimedia Processing Course - Part 4: Video Processing\n",
                "\n",
                "Video is a sequence of images. In this notebook, we will process video frame by frame and detect motion.\n",
                "\n",
                "**Content:**\n",
                "1.  **Level 1 (Basic)**: Reading Video and accessing properties.\n",
                "2.  **Level 2 (Intermediate)**: Processing frames (Grayscale conversion).\n",
                "3.  **Level 3 (Advanced)**: Motion Detection using Frame Differencing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "video_path = 'datasets/sample_video.mp4'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Level 1: Reading Video Properties\n",
                "Before processing, let's understand our video file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cap = cv2.VideoCapture(video_path)\n",
                "\n",
                "fps = cap.get(cv2.CAP_PROP_FPS)\n",
                "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
                "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
                "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
                "\n",
                "print(f\"FPS: {fps}\")\n",
                "print(f\"Total Frames: {frame_count}\")\n",
                "print(f\"Resolution: {width}x{height}\")\n",
                "\n",
                "cap.release()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "We use `cap.get()` with property IDs like `cv2.CAP_PROP_FPS` to retrieve metadata."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Level 2: Processing Frames\n",
                "We can loop through the video and process each frame. Let's convert a few frames to grayscale and display them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cap = cv2.VideoCapture(video_path)\n",
                "\n",
                "# Read the first 5 frames\n",
                "for i in range(5):\n",
                "    ret, frame = cap.read()\n",
                "    if not ret:\n",
                "        break\n",
                "    \n",
                "    # Convert to grayscale\n",
                "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
                "    \n",
                "    # Display strictly the 1st and 5th frame to save space\n",
                "    if i == 0 or i == 4:\n",
                "        plt.imshow(gray, cmap='gray')\n",
                "        plt.title(f\"Frame {i+1} (Grayscale)\")\n",
                "        plt.axis('off')\n",
                "        plt.show()\n",
                "\n",
                "cap.release()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "We use a `while` or `for` loop to read frames. `cap.read()` advances the video pointer automatically."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Level 3: Simple Motion Detection\n",
                "Idea: If a pixel changes significantly between two consecutive frames, it's moving.\n",
                "We will compute the absolute difference between Frame N and Frame N-1."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cap = cv2.VideoCapture(video_path)\n",
                "\n",
                "# Read first frame\n",
                "ret, prev_frame = cap.read()\n",
                "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
                "\n",
                "frame_idx = 0\n",
                "while True:\n",
                "    ret, frame = cap.read()\n",
                "    if not ret:\n",
                "        break\n",
                "        \n",
                "    frame_idx += 1\n",
                "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
                "    \n",
                "    # Compute absolute difference\n",
                "    diff = cv2.absdiff(prev_gray, gray)\n",
                "    \n",
                "    # Threshold to get binay motion mask\n",
                "    _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
                "    \n",
                "    # Update previous frame\n",
                "    prev_gray = gray\n",
                "    \n",
                "    # Display results for a specific frame (e.g., frame 50)\n",
                "    if frame_idx == 50:\n",
                "        plt.figure(figsize=(10,5))\n",
                "        plt.subplot(1, 2, 1)\n",
                "        plt.imshow(frame, cmap='gray') # Displaying raw frame (BGR interpreted as RGB looks weird but shape is visible)\n",
                "        plt.title(\"Original Frame 50\")\n",
                "        \n",
                "        plt.subplot(1, 2, 2)\n",
                "        plt.imshow(thresh, cmap='gray')\n",
                "        plt.title(\"Motion Mask\")\n",
                "        plt.show()\n",
                "\n",
                "cap.release()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "1.  `cv2.absdiff`: Finds absolute difference between two arrays.\n",
                "2.  `cv2.threshold`: Converts the difference to black (no motion) and white (motion) based on a threshold (25 in this case).\n",
                "White areas in the Motion Mask represent movement."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}