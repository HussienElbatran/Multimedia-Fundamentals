{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multimedia Processing Course - Part 2: Image Processing\n",
                "\n",
                "In this notebook, we dive deeper into processing images. We will go from basic pixel manipulation to extracting features like edges.\n",
                "\n",
                "**Content:**\n",
                "1.  **Level 1 (Basic)**: Reading, Writing, and Color Spaces.\n",
                "2.  **Level 2 (Intermediate)**: Geometric Transformations and Histograms.\n",
                "3.  **Level 3 (Advanced)**: Filtering and Edge Detection."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Setup for displaying images properly in notebook\n",
                "def show_image(img, title=\"Image\", cmap_type=None):\n",
                "    plt.imshow(img, cmap=cmap_type)\n",
                "    plt.title(title)\n",
                "    plt.axis('off')\n",
                "    plt.show()\n",
                "\n",
                "# Load our sample image\n",
                "image = cv2.imread('datasets/sample_image.jpg')\n",
                "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
                "show_image(image_rgb, \"Original Image\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "We defined a helper function `show_image` to avoid repeating plot code. We loaded the image and converted it to RGB for display."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Level 1: Color Spaces\n",
                "Images can be represented in different color spaces. The most common are RGB, Grayscale, and HSV (Hue, Saturation, Value)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert to Grayscale\n",
                "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
                "show_image(gray_image, \"Grayscale Image\", 'gray')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "`cv2.cvtColor` with `cv2.COLOR_BGR2GRAY` converts the color image to grayscale. It's a 2D array now instead of 3D."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert to HSV\n",
                "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
                "# HSV is hard to visualize directly with RGB viewers, but let's see it\n",
                "show_image(hsv_image, \"HSV Image\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "HSV separates color information (Hue) from intensity (Value). This is very useful for color-based object tracking."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Level 2: Geometric Transformations\n",
                "We can resize, rotate, and crop images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Resizing\n",
                "height, width = image.shape[:2]\n",
                "new_dim = (int(width / 2), int(height / 2)) # Half size\n",
                "\n",
                "resized_image = cv2.resize(image_rgb, new_dim)\n",
                "show_image(resized_image, f\"Resized to {new_dim}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "`cv2.resize()` takes the image and the new dimensions (width, height)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Rotation\n",
                "center = (width // 2, height // 2)\n",
                "angle = 45\n",
                "scale = 1.0\n",
                "\n",
                "# Get rotation matrix\n",
                "M = cv2.getRotationMatrix2D(center, angle, scale)\n",
                "\n",
                "# Apply rotation\n",
                "rotated_image = cv2.warpAffine(image_rgb, M, (width, height))\n",
                "show_image(rotated_image, \"Rotated Image\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "Rotation requires a matrix. `cv2.getRotationMatrix2D` creates it. `cv2.warpAffine` applies the transformation."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Level 3: Filtering and Edges\n",
                "Filtering helps remove noise. Edge detection finds boundaries."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Gaussian Blur (Smoothing)\n",
                "blurred_image = cv2.GaussianBlur(image_rgb, (15, 15), 0)\n",
                "show_image(blurred_image, \"Blurred Image\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "`cv2.GaussianBlur` smoothes the image using a Gaussian kernel. `(15, 15)` is the kernel size (must be odd)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Canny Edge Detection\n",
                "# We use the grayscale image for edge detection\n",
                "edges = cv2.Canny(gray_image, 100, 200)\n",
                "show_image(edges, \"Canny Edges\", 'gray')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explanation\n",
                "`cv2.Canny` finds edges. `100` and `200` are the lower and upper thresholds for the hysteresis procedure. White pixels are edges."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}